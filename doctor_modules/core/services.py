import logging
import shutil
from orchestrator import PROJECT_FOLDER
from core.history_manager import save_proposal
from core.client import (
    query_huggingface_model,
    query_openai_model,
    query_mistral_api_model,
    query_cohere_model,
    query_google_model,
    query_aws_model,
    query_deepl_translation
)
from decouple import config

MODEL_GPT4 = "gpt-4"
MODEL_GPT35 = "gpt-3.5-turbo"

custom_objectives = ""


def load_readme():
    global custom_objectives
    if README_PATH and README_PATH.endswith(".md"):
        try:
            with open(README_PATH, "r", encoding="utf-8") as f:
                custom_objectives = f.read()
                logging.info("üìñ Objectifs utilisateur charg√©s depuis README.md")
        except Exception as e:
            logging.warning(f"Impossible de lire le README.md : {e}")


def get_best_available_model(prompt: str = ""):
    if len(prompt) > 1000:
        if config("MISTRAL_API_KEY", default=None):
            return "MISTRAL"
        if config("COHERE_API_KEY", default=None):
            return "COHERE"

    if config("OPENAI_API_KEY", default=None):
        return "OPENAI"
    if config("MISTRAL_API_KEY", default=None):
        return "MISTRAL"
    if config("COHERE_API_KEY", default=None):
        return "COHERE"
    if config("GOOGLE_API_KEY", default=None):
        return "GOOGLE"
    if config("HUGGINGFACE_API_KEY", default=None):
        return "HUGGINGFACE"
    if config("AWS_API_KEY", default=None):
        return "AWS"
    return None


def build_messages(code, filename):
    return [
        {"role": "system", "content": "Tu es une IA experte en am√©lioration de code Python. Reste claire, concise et utile."},
        {"role": "user", "content": f"Voici le fichier {filename} √† am√©liorer :\n{code}\n\n{custom_objectives}"}
    ]


def is_complex_request(message: str) -> bool:
    long_msg = len(message) > 500
    has_keywords = any(word in message.lower() for word in [
        "r√©sume", "analyse", "explique", "corrige", "am√©liore", "optimise", "comparer", "strat√©gie"
    ])
    return long_msg or has_keywords


def translate_text(text: str, target_lang: str = "EN") -> str:
    try:
        return query_deepl_translation(text, target_lang)
    except Exception as e:
        logging.warning(f"Erreur traduction DeepL : {e}")
        return text


def generate_code_proposal(code, filename):
    print("üß™ La fonction generate_code_proposal() a bien √©t√© appel√©e")
    provider = get_best_available_model()
    messages = build_messages(code, filename)
    prompt = "\n".join(m["content"] for m in messages if m["role"] == "user")

    if provider == "OPENAI":
        try:
            chosen_model = MODEL_GPT4 if is_complex_request(prompt) else MODEL_GPT35
            print(f"üß† Utilisation du mod√®le OpenAI : {chosen_model}")
            suggestion = query_openai_model(prompt, model=chosen_model)
            save_proposal(filename, code, suggestion, accepted=False)
            return suggestion
        except Exception as e:
            logging.error(f"‚ùå Erreur OpenAI : {e}")
            return f"Erreur OpenAI : {e}"

    elif provider == "MISTRAL":
        print("üî∑ Utilisation de Mistral 7B via HuggingFace")
        return query_mistral_api_model(prompt)

    elif provider == "COHERE":
        print("üü£ Utilisation de Cohere")
        return query_cohere_model(prompt)

    elif provider == "GOOGLE":
        print("üü¢ Utilisation de Google Gemini")
        return query_google_model(prompt)

    elif provider == "HUGGINGFACE":
        print("üü° Utilisation de HuggingFace (gpt2 par d√©faut)")
        return query_huggingface_model("gpt2", prompt)

    elif provider == "AWS":
        print("üü† AWS activ√© (fonction √† impl√©menter)")
        return query_aws_model(prompt)

    else:
        logging.warning("‚ö†Ô∏è Aucune cl√© API valide d√©tect√©e.")
        return "Aucune cl√© API valide d√©tect√©e pour g√©n√©rer une proposition."


def backup_file(filepath):
    backup_path = filepath + ".bak"
    try:
        shutil.copy2(filepath, backup_path)
        logging.info(f"üóÇÔ∏è Copie de sauvegarde cr√©√©e : {backup_path}")
    except Exception as e:
        logging.error(f"‚ùå Erreur lors de la cr√©ation de la sauvegarde : {e}")
