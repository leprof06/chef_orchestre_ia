import os
import json
import logging
from pathlib import Path
from datetime import datetime
from uuid import uuid4
from config.config import PROJECT_FOLDER
from core.client import query_openai_model  # utilis√© pour les r√©sum√©s

# üîç Config
HISTORY_FILE = Path(PROJECT_FOLDER) / Path("H:/IA/IA programeuse/data/history.json")
ARCHIVE_FOLDER = Path(PROJECT_FOLDER) / Path("H:/IA/IA programeuse/data/archives")
INDEX_FILE = Path(PROJECT_FOLDER) / Path("H:/IA/IA programeuse/data/history_index.json")
MAX_SIZE_MB = 500  # üí° Ajuste ici si tu veux une taille plus petite ou plus grande

ARCHIVE_FOLDER.mkdir(parents=True, exist_ok=True)
logger = logging.getLogger("history_archiver")
logger.setLevel(logging.INFO)


def get_file_size_mb(file_path):
    return os.path.getsize(file_path) / (1024 * 1024)


def summarize_suggestion(entry):
    content = entry.get("suggestion", "")[:1500]
    prompt = f"Voici une suggestion de l'IA :\n{content}\n\nFais-en un r√©sum√© en une phrase claire et concise."
    try:
        return query_openai_model(prompt)
    except Exception as e:
        logger.warning(f"‚ùå Erreur r√©sum√© OpenAI : {e}")
        return "Suggestion IA r√©sum√©e (erreur OpenAI)"


def load_history():
    if not HISTORY_FILE.exists():
        return []
    with open(HISTORY_FILE, encoding="utf-8") as f:
        try:
            return json.load(f)
        except json.JSONDecodeError:
            logger.error("‚ùå Erreur lors du chargement de history.json")
            return []


def save_archive(data):
    archive_name = f"history_archive_{uuid4().hex[:8]}.json"
    archive_path = ARCHIVE_FOLDER / archive_name
    with open(archive_path, "w", encoding="utf-8") as f:
        json.dump(data, f, indent=2, ensure_ascii=False)
    logger.info(f"üîÑ Archive enregistr√©e : {archive_name}")
    return archive_name


def update_index(entries, archive_name):
    index_data = {}
    if INDEX_FILE.exists():
        with open(INDEX_FILE, encoding="utf-8") as f:
            try:
                index_data = json.load(f)
            except json.JSONDecodeError:
                logger.warning("‚ö†Ô∏è Fichier index corrompu. Remplacement...")

    for entry in entries:
        name = entry.get("filename", f"unknown_{uuid4().hex[:6]}.py")
        index_data[name] = {
            "status": "archiv√©",
            "archive": archive_name,
            "summary": summarize_suggestion(entry),
            "date": datetime.now().isoformat()
        }

    with open(INDEX_FILE, "w", encoding="utf-8") as f:
        json.dump(index_data, f, indent=2, ensure_ascii=False)
    logger.info("üìÑ Index mis √† jour.")


def archive_history_if_needed():
    if not HISTORY_FILE.exists():
        logger.warning("Aucun fichier history.json trouv√©.")
        return

    size_mb = get_file_size_mb(HISTORY_FILE)
    if size_mb < MAX_SIZE_MB:
        logger.info(f"‚úÖ Taille correcte ({size_mb:.2f} Mo)")
        return

    logger.warning(f"üö® Taille ({size_mb:.2f} Mo) trop grande. Archivage...")
    history_data = load_history()

    if not history_data:
        logger.warning("‚ö†Ô∏è Aucun contenu √† archiver.")
        return

    archive_name = save_archive(history_data)
    update_index(history_data, archive_name)

    try:
        with open(HISTORY_FILE, "w", encoding="utf-8") as f:
            json.dump([], f, indent=2)
        logger.info("‚úÖ Fichier history.json vid√© avec succ√®s.")
    except Exception as e:
        logger.error(f"‚ùå Impossible de vider le fichier history.json : {e}")


if __name__ == "__main__":
    archive_history_if_needed()
